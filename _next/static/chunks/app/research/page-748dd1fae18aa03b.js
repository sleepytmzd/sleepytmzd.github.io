(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[322],{2300:(e,a,s)=>{"use strict";s.r(a),s.d(a,{default:()=>m});var i=s(5155),n=s(5923),t=s(9946);let r=(0,t.A)("book-open-check",[["path",{d:"M12 21V7",key:"gj6g52"}],["path",{d:"m16 12 2 2 4-4",key:"mdajum"}],["path",{d:"M22 6V4a1 1 0 0 0-1-1h-5a4 4 0 0 0-4 4 4 4 0 0 0-4-4H3a1 1 0 0 0-1 1v13a1 1 0 0 0 1 1h6a3 3 0 0 1 3 3 3 3 0 0 1 3-3h6a1 1 0 0 0 1-1v-1.3",key:"8arnkb"}]]),l=(0,t.A)("link-2",[["path",{d:"M9 17H7A5 5 0 0 1 7 7h2",key:"8i5ue5"}],["path",{d:"M15 7h2a5 5 0 1 1 0 10h-2",key:"1b9ql8"}],["line",{x1:"8",x2:"16",y1:"12",y2:"12",key:"1jonct"}]]);var o=s(3332),c=s(6874),d=s.n(c);function m(){return(0,i.jsxs)("div",{className:"max-w-5xl mx-auto px-4 sm:px-6 py-8",children:[(0,i.jsx)(n.A,{distance:100,direction:"vertical",reverse:!1,duration:1.2,ease:"power3.out",initialOpacity:0,animateOpacity:!0,scale:1,threshold:.1,delay:0,children:(0,i.jsxs)("div",{className:"card p-4 sm:p-6 rounded-lg my-6",children:[(0,i.jsxs)("div",{className:"flex flex-col md:flex-row md:items-center justify-between gap-4",children:[(0,i.jsxs)("div",{className:"flex items-start md:items-center gap-4",children:[(0,i.jsx)("span",{className:"icon-wrapper",children:(0,i.jsx)(r,{size:20})}),(0,i.jsxs)("div",{children:[(0,i.jsx)("h3",{className:"text-lg sm:text-xl md:text-2xl font-bold leading-tight",children:"Too Late to Train, Too Early To Use?"}),(0,i.jsx)("div",{className:"muted text-sm sm:text-base mt-1",children:"A Study on Necessity and Viability of Low-Resource Bengali LLMs"})]})]}),(0,i.jsx)("div",{className:"flex items-center gap-3",children:(0,i.jsx)(d(),{href:"https://arxiv.org/abs/2407.00416",target:"_blank",rel:"noopener noreferrer","aria-label":"Open paper",children:(0,i.jsxs)("span",{className:"link-btn",children:[(0,i.jsx)(l,{size:16}),(0,i.jsx)("span",{className:"sr-only",children:"Open paper"})]})})})]}),(0,i.jsxs)("div",{className:"flex flex-wrap gap-3 items-center mt-4",children:[(0,i.jsx)("span",{className:"icon-wrapper",children:(0,i.jsx)(o.A,{size:18})}),(0,i.jsx)("div",{className:"badge",children:"Natural Language Processing"}),(0,i.jsx)("div",{className:"badge",children:"LLMs"})]}),(0,i.jsxs)("div",{className:"desc mt-4 text-sm sm:text-base",children:[(0,i.jsx)("strong",{children:"Abstract:"})," ","Each new generation of English-oriented Large Language Models (LLMs) exhibits enhanced cross-lingual transfer capabilities and significantly outperforms older LLMs on low-resource languages. This prompts the question: Is there a need for LLMs dedicated to a particular low-resource language? We aim to explore this question for Bengali, a low-to-moderate resource Indo-Aryan language native to the Bengal region of South Asia. We compare the performance of open-weight and closed-source LLMs such as LLaMA-3 and GPT-4 against fine-tuned encoder-decoder models across a diverse set of Bengali downstream tasks, including translation, summarization, paraphrasing, question-answering, and natural language inference. Our findings reveal that while LLMs generally excel in reasoning tasks, their performance in tasks requiring Bengali script generation is inconsistent. Key challenges include inefficient tokenization of Bengali script by existing LLMs, leading to increased computational costs and potential performance degradation. Additionally, we highlight biases in machine-translated datasets commonly used for Bengali NLP tasks. We conclude that there is a significant need for a Bengali-oriented LLM, but the field currently lacks the high-quality pretraining and instruction-tuning datasets necessary to develop a highly effective model."]})]})}),(0,i.jsx)(n.A,{distance:100,direction:"vertical",reverse:!1,duration:1.2,ease:"power3.out",initialOpacity:0,animateOpacity:!0,scale:1,threshold:.1,delay:.1,children:(0,i.jsxs)("div",{className:"card p-4 sm:p-6 rounded-lg my-6",children:[(0,i.jsxs)("div",{className:"flex flex-col md:flex-row md:items-center justify-between gap-4",children:[(0,i.jsxs)("div",{className:"flex items-start md:items-center gap-4",children:[(0,i.jsx)("span",{className:"icon-wrapper",children:(0,i.jsx)(r,{size:20})}),(0,i.jsxs)("div",{children:[(0,i.jsx)("h3",{className:"text-lg sm:text-xl md:text-2xl font-bold leading-tight",children:"Efficient Real-Time Video Colorization on Low-End CPUs via Pruning and Quantization"}),(0,i.jsx)("div",{className:"muted text-sm sm:text-base mt-1",children:"Conference paper â€” real-time colorization on CPUs"})]})]}),(0,i.jsx)("div",{className:"flex items-center gap-3",children:(0,i.jsx)(d(),{href:"https://dl.acm.org/doi/10.1145/3704522.3704536",target:"_blank",rel:"noopener noreferrer","aria-label":"Open paper",children:(0,i.jsxs)("span",{className:"link-btn",children:[(0,i.jsx)(l,{size:16}),(0,i.jsx)("span",{className:"sr-only",children:"Open paper"})]})})})]}),(0,i.jsxs)("div",{className:"flex flex-wrap gap-3 items-center mt-4",children:[(0,i.jsx)("span",{className:"icon-wrapper",children:(0,i.jsx)(o.A,{size:14})}),(0,i.jsx)("div",{className:"badge",children:"Computer Vision"}),(0,i.jsx)("div",{className:"badge",children:"Deep Learning"}),(0,i.jsx)("div",{className:"badge",children:"Neural Networks"})]}),(0,i.jsxs)("div",{className:"desc mt-4 text-sm sm:text-base",children:[(0,i.jsx)("strong",{children:"Abstract:"})," ","Grayscale video capture remains a popular, low-cost approach for security and surveillance-related tasks, especially on edge devices. We create a deep-learning solution to colorize grayscale videos in real-time without dedicated acceleration hardware such as GPUs. We first trained EfficientNet-B7-based U-Net on a combination of image and video datasets. We prune redundant parameters in the bottleneck layers of the trained neural network using weight-base pruning, followed by minimal training to recover performance. Finally, we quantize parts of the neural network which reduces model size and inference-time memory requirement. Our final optimized model achieves a 43.75% inference speed improvement and 30.6% model size reduction over the base model and can colorize videos at 6+ frames per second on low-end CPUs while maintaining a competitive CDC score of 0.0031 and PSNR of 19."]})]})})]})}},3332:(e,a,s)=>{"use strict";s.d(a,{A:()=>i});let i=(0,s(9946).A)("tag",[["path",{d:"M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z",key:"vktsd0"}],["circle",{cx:"7.5",cy:"7.5",r:".5",fill:"currentColor",key:"kqv944"}]])},5923:(e,a,s)=>{"use strict";s.d(a,{A:()=>l});var i=s(5155),n=s(2115),t=s(802),r=s(9088);t.os.registerPlugin(r.u);let l=e=>{let{children:a,distance:s=100,direction:l="vertical",reverse:o=!1,duration:c=.8,ease:d="power3.out",initialOpacity:m=0,animateOpacity:h=!0,scale:p=1,threshold:g=.1,delay:u=0,onComplete:x}=e,f=(0,n.useRef)(null);return(0,n.useEffect)(()=>{let e=f.current;if(!e)return;let a="horizontal"===l?"x":"y",i=o?-s:s,n=(1-g)*100;return t.os.set(e,{[a]:i,scale:p,opacity:h?m:1}),t.os.to(e,{[a]:0,scale:1,opacity:1,duration:c,ease:d,delay:u,onComplete:x,scrollTrigger:{trigger:e,start:"top ".concat(n,"%"),toggleActions:"play none none none",once:!0}}),()=>{r.u.getAll().forEach(e=>e.kill()),t.os.killTweensOf(e)}},[s,l,o,c,d,m,h,p,g,u,x]),(0,i.jsx)("div",{ref:f,children:a})}},7283:(e,a,s)=>{Promise.resolve().then(s.bind(s,2300))}},e=>{var a=a=>e(e.s=a);e.O(0,[592,737,95,441,684,358],()=>a(7283)),_N_E=e.O()}]);